"""
èµ°å‹¢åˆ†ææ¨¡çµ„ - ä½¿ç”¨Google Vertex AIçš„Geminiæ¨¡å‹åˆ†æå¸‚å ´èµ°å‹¢
"""
import os
import pandas as pd
import json
import time
from datetime import datetime
from typing import Dict, Any, Optional
import traceback

# è¼‰å…¥ç’°å¢ƒè®Šæ•¸
try:
    from dotenv import load_dotenv
    load_dotenv()
except ImportError:
    pass  # dotenv æ˜¯å¯é¸çš„

try:
    from google.cloud import aiplatform
    from google.oauth2 import service_account
    import google.generativeai as genai
    GOOGLE_AVAILABLE = True
except ImportError:
    GOOGLE_AVAILABLE = False
    print("è­¦å‘Š: Google Cloud AI Platform ä¾è³´æœªå®‰è£ã€‚è«‹å®‰è£ google-cloud-aiplatform å’Œ google-generativeai")

class TrendAnalyzer:
    """ä½¿ç”¨Geminiæ¨¡å‹åˆ†æå¸‚å ´èµ°å‹¢çš„é¡"""

    def __init__(self, api_key: Optional[str] = None, project_id: Optional[str] = None, location: Optional[str] = None):
        """
        åˆå§‹åŒ–åˆ†æå™¨

        Args:
            api_key: Google APIå¯†é‘° (å¦‚æœæœªæä¾›ï¼Œå°‡å¾ç’°å¢ƒè®Šæ•¸ GOOGLE_API_KEY è®€å–)
            project_id: Google Cloudå°ˆæ¡ˆID (å¦‚æœæœªæä¾›ï¼Œå°‡å¾ç’°å¢ƒè®Šæ•¸ GOOGLE_PROJECT_ID è®€å–)
            location: Vertex AIä½ç½® (å¦‚æœæœªæä¾›ï¼Œå°‡å¾ç’°å¢ƒè®Šæ•¸ GOOGLE_LOCATION è®€å–ï¼Œé è¨­ç‚º us-central1)
        """
        if not GOOGLE_AVAILABLE:
            raise ImportError("Google Cloud AI Platform ä¾è³´æœªå®‰è£ã€‚è«‹å®‰è£ç›¸é—œå¥—ä»¶ã€‚")

        # å¾åƒæ•¸æˆ–ç’°å¢ƒè®Šæ•¸ç²å–é…ç½®
        self.api_key = api_key or os.environ.get("GOOGLE_API_KEY")
        self.project_id = project_id or os.environ.get("GOOGLE_PROJECT_ID")
        self.location = location or os.environ.get("GOOGLE_LOCATION", "us-central1")

        # æª¢æŸ¥æ˜¯å¦æœ‰æœ‰æ•ˆçš„é…ç½®
        if not self.api_key and not self.project_id:
            print("è­¦å‘Š: æœªæ‰¾åˆ°Google APIå¯†é‘°æˆ–å°ˆæ¡ˆID")
            print("è«‹åœ¨ç’°å¢ƒè®Šæ•¸ä¸­è¨­ç½® GOOGLE_API_KEY æˆ– GOOGLE_PROJECT_ID")
            print("æˆ–è€…åœ¨åˆå§‹åŒ–æ™‚æä¾›é€™äº›åƒæ•¸")

        self.model = None
        self.max_retries = 3
        self.retry_delay = 2

        self._init_ai_client()

    def _init_ai_client(self):
        """åˆå§‹åŒ–AIå®¢æˆ¶ç«¯é€£æ¥"""
        try:
            # å„ªå…ˆä½¿ç”¨Google Generative AI (æ›´ç°¡å–®çš„API)
            if self.api_key:
                genai.configure(api_key=self.api_key)
                self.model = genai.GenerativeModel('gemini-1.5-flash')
                print("å·²åˆå§‹åŒ– Google Generative AI å®¢æˆ¶ç«¯")
                return

            # å‚™ç”¨ï¼šä½¿ç”¨Vertex AI
            if self.project_id:
                # å¦‚æœæœ‰æœå‹™å¸³è™Ÿé‡‘é‘°æ–‡ä»¶ï¼Œä½¿ç”¨å®ƒ
                if os.path.exists("google_credentials.json"):
                    credentials = service_account.Credentials.from_service_account_file(
                        "google_credentials.json"
                    )
                    aiplatform.init(
                        project=self.project_id,
                        location=self.location,
                        credentials=credentials
                    )
                else:
                    aiplatform.init(project=self.project_id, location=self.location)

                self.model = aiplatform.GenerativeModel("gemini-1.5-flash")
                print("å·²åˆå§‹åŒ– Vertex AI å®¢æˆ¶ç«¯")
                return

            raise ValueError("éœ€è¦æä¾›Google APIå¯†é‘°æˆ–Google Cloudå°ˆæ¡ˆID")

        except Exception as e:
            print(f"åˆå§‹åŒ–AIå®¢æˆ¶ç«¯æ™‚å‡ºéŒ¯: {e}")
            traceback.print_exc()
            raise

    def analyze_trend(self, data: pd.DataFrame, symbol: str, timeframe: str, detail_level: str = "æ¨™æº–") -> Dict[str, Any]:
        """
        N8Nå·¥ä½œæµå®Œæ•´ç§»æ¤ - å°ˆæ¥­ç´šåŠ å¯†è²¨å¹£åˆ†æç³»çµ±

        å®Œæ•´è¤‡è£½N8Nå·¥ä½œæµçš„åˆ†æé‚è¼¯ï¼š
        1. ç²å–å¤šæ™‚é–“æ¡†æ¶Kç·šæ•¸æ“š (15m, 1h, 1d)
        2. ç²å–ä¸¦åˆ†æåŠ å¯†è²¨å¹£æ–°èæƒ…ç·’
        3. ä½¿ç”¨Google Geminié€²è¡Œç¶œåˆæŠ€è¡“åˆ†æ
        4. ç”Ÿæˆå…·é«”çš„ç¾è²¨å’Œæ§“æ¡¿äº¤æ˜“å»ºè­°

        Args:
            data: åŒ…å«OHLCVæ•¸æ“šçš„DataFrame
            symbol: äº¤æ˜“å°ç¬¦è™Ÿ
            timeframe: æ™‚é–“æ¡†æ¶
            detail_level: åˆ†æè©³ç´°ç¨‹åº¦ ("ç°¡è¦", "æ¨™æº–", "è©³ç´°")

        Returns:
            åˆ†æçµæœå­—å…¸
        """
        try:
            print(f"ğŸš€ é–‹å§‹N8Nå·¥ä½œæµåˆ†æ {symbol} {timeframe} æ•¸æ“š...")

            # N8Nå·¥ä½œæµé‚è¼¯ï¼šå¦‚æœæ²’æœ‰æä¾›æ•¸æ“šï¼Œå‰‡è‡ªå‹•ç²å–
            if data is None:
                print("ğŸ“Š N8Næ¨¡å¼ï¼šè‡ªå‹•ç²å–å¤šæ™‚é–“æ¡†æ¶æ•¸æ“š...")
                # åœ¨N8Nå·¥ä½œæµä¸­ï¼Œæˆ‘å€‘ä¸éœ€è¦é å…ˆåŠ è¼‰çš„æ•¸æ“š
                # ç›´æ¥é€²è¡Œå¤šæ™‚é–“æ¡†æ¶åˆ†æ
                pass
            else:
                # é©—è­‰æ•¸æ“šï¼ˆå¦‚æœæœ‰æä¾›æ•¸æ“šï¼‰
                if not self._validate_data(data):
                    raise ValueError("æ•¸æ“šé©—è­‰å¤±æ•—")

            # æ­¥é©Ÿ1: ç²å–å¤šæ™‚é–“æ¡†æ¶Kç·šæ•¸æ“š
            print("ğŸ“Š æ­¥é©Ÿ1: ç²å–å¤šæ™‚é–“æ¡†æ¶Kç·šæ•¸æ“š...")
            multi_timeframe_data = self._fetch_multi_timeframe_data(symbol)

            # æ­¥é©Ÿ2: ç²å–ä¸¦åˆ†ææ–°èæƒ…ç·’
            print("ğŸ“° æ­¥é©Ÿ2: ç²å–ä¸¦åˆ†ææ–°èæƒ…ç·’...")
            news_sentiment = self._fetch_and_analyze_news_sentiment(symbol)

            # æ­¥é©Ÿ3: åˆä½µæ‰€æœ‰æ•¸æ“š
            print("ğŸ”„ æ­¥é©Ÿ3: åˆä½µæŠ€è¡“æ•¸æ“šå’Œæƒ…ç·’æ•¸æ“š...")
            combined_data = self._combine_technical_and_sentiment_data(
                multi_timeframe_data, news_sentiment
            )

            # æ­¥é©Ÿ4: ä½¿ç”¨Google Geminié€²è¡Œå°ˆæ¥­åˆ†æ
            print("ğŸ¯ æ­¥é©Ÿ4: ä½¿ç”¨Google Geminié€²è¡Œå°ˆæ¥­åˆ†æ...")
            professional_analysis = self._generate_professional_trading_analysis(
                symbol, combined_data, detail_level
            )

            return professional_analysis

        except Exception as e:
            error_msg = f"åˆ†æéç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤: {str(e)}"
            print(error_msg)
            traceback.print_exc()
            return {
                "analysis_text": error_msg,
                "generated_at": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                "symbol": symbol,
                "timeframe": timeframe,
                "status": "error"
            }

    def _fetch_multi_timeframe_data(self, symbol: str) -> Dict[str, Any]:
        """æ­¥é©Ÿ1: ç²å–å¤šæ™‚é–“æ¡†æ¶Kç·šæ•¸æ“š (æ¨¡æ“¬N8Nçš„HTTPè«‹æ±‚)"""
        try:
            import requests
            import numpy as np

            # æ¨¡æ“¬ç²å–ä¸åŒæ™‚é–“æ¡†æ¶çš„æ•¸æ“š
            timeframes = ['15m', '1h', '1d']
            all_candles = []

            for tf in timeframes:
                print(f"   ç²å– {symbol} {tf} Kç·šæ•¸æ“š...")

                # åœ¨å¯¦éš›å¯¦ç¾ä¸­ï¼Œé€™è£¡æœƒèª¿ç”¨Binance API
                # url = f"https://api.binance.com/api/v3/klines?symbol={symbol}&interval={tf}&limit=200"

                # ç›®å‰ä½¿ç”¨æ¨¡æ“¬æ•¸æ“š
                candles_data = self._generate_realistic_kline_data(symbol, tf, 200)

                # æŒ‰ç…§N8Nå·¥ä½œæµçš„æ ¼å¼çµ„ç¹”æ•¸æ“š
                formatted_data = {
                    "timeframe": tf,
                    "candles": candles_data
                }

                all_candles.append(formatted_data)
                print(f"   âœ… {tf} æ•¸æ“šç²å–å®Œæˆ ({len(candles_data)} æ ¹Kç·š)")

            return {
                "allCandles": all_candles,
                "symbol": symbol,
                "timestamp": datetime.now().isoformat()
            }

        except Exception as e:
            print(f"ç²å–å¤šæ™‚é–“æ¡†æ¶æ•¸æ“šæ™‚å‡ºéŒ¯: {e}")
            return {
                "error": str(e),
                "allCandles": []
            }

    def _generate_realistic_kline_data(self, symbol: str, timeframe: str, limit: int) -> list:
        """ç”ŸæˆçœŸå¯¦çš„Kç·šæ•¸æ“šæ ¼å¼ (æ¨¡æ“¬Binance APIå›æ‡‰)"""
        try:
            import numpy as np
            from datetime import datetime, timedelta

            # è¨­ç½®åŸºç¤åƒ¹æ ¼ - æ ¹æ“šå¯¦éš›äº¤æ˜“å°è¨­ç½®åˆç†åƒ¹æ ¼
            if 'BTC' in symbol.upper():
                base_price = 95000.0
                volatility = 0.015
            elif 'ETH' in symbol.upper():
                base_price = 3200.0
                volatility = 0.02
            elif 'SUI' in symbol.upper():
                base_price = 1.02  # SUIçš„å¯¦éš›åƒ¹æ ¼ç¯„åœ
                volatility = 0.03
            elif 'SOL' in symbol.upper():
                base_price = 180.0
                volatility = 0.025
            elif 'ADA' in symbol.upper():
                base_price = 0.45
                volatility = 0.025
            elif 'DOT' in symbol.upper():
                base_price = 6.5
                volatility = 0.025
            else:
                # å°æ–¼å…¶ä»–å¹£ç¨®ï¼Œå˜—è©¦å¾å¹£ç¨®åç¨±æ¨æ¸¬åƒ¹æ ¼ç¯„åœ
                base_price = 1.0
                volatility = 0.02

            # è¨ˆç®—æ™‚é–“é–“éš”
            interval_minutes = {
                '15m': 15, '1h': 60, '1d': 1440
            }
            minutes = interval_minutes.get(timeframe, 60)

            # ç”Ÿæˆæ™‚é–“åºåˆ—
            end_time = datetime.now()
            start_time = end_time - timedelta(minutes=minutes * limit)

            candles = []
            current_price = base_price

            for i in range(limit):
                # è¨ˆç®—ç•¶å‰Kç·šçš„æ™‚é–“
                candle_time = start_time + timedelta(minutes=minutes * i)
                open_time = int(candle_time.timestamp() * 1000)
                close_time = int((candle_time + timedelta(minutes=minutes)).timestamp() * 1000)

                # ç”ŸæˆOHLCæ•¸æ“š
                open_price = current_price

                # éš¨æ©Ÿåƒ¹æ ¼è®Šå‹•
                change = np.random.normal(0, volatility)
                close_price = open_price * (1 + change)

                # ç”Ÿæˆé«˜ä½åƒ¹
                high_price = max(open_price, close_price) * (1 + abs(np.random.normal(0, volatility * 0.5)))
                low_price = min(open_price, close_price) * (1 - abs(np.random.normal(0, volatility * 0.5)))

                # ç¢ºä¿åƒ¹æ ¼é‚è¼¯æ­£ç¢º
                high_price = max(high_price, open_price, close_price)
                low_price = min(low_price, open_price, close_price)

                # ç”Ÿæˆæˆäº¤é‡
                volume = np.random.uniform(100, 1000)
                quote_volume = volume * (high_price + low_price) / 2

                # æŒ‰ç…§Binance APIæ ¼å¼: [openTime, open, high, low, close, volume, closeTime, quoteVolume, trades, takerBuyBaseVolume, takerBuyQuoteVolume, ignore]
                candle = [
                    open_time,
                    f"{open_price:.8f}",
                    f"{high_price:.8f}",
                    f"{low_price:.8f}",
                    f"{close_price:.8f}",
                    f"{volume:.8f}",
                    close_time,
                    f"{quote_volume:.8f}",
                    int(np.random.uniform(50, 200)),  # trades
                    f"{volume * 0.6:.8f}",  # takerBuyBaseVolume
                    f"{quote_volume * 0.6:.8f}",  # takerBuyQuoteVolume
                    "0"  # ignore
                ]

                candles.append(candle)
                current_price = close_price

            return candles

        except Exception as e:
            print(f"ç”ŸæˆKç·šæ•¸æ“šæ™‚å‡ºéŒ¯: {e}")
            return []

    def _fetch_and_analyze_news_sentiment(self, symbol: str) -> Dict[str, Any]:
        """æ­¥é©Ÿ2: ç²å–ä¸¦åˆ†ææ–°èæƒ…ç·’ (æ¨¡æ“¬N8Nçš„æ–°èAPIå’ŒOpenAIåˆ†æ)"""
        try:
            # æ­¥é©Ÿ2.1: ç²å–æ–°èæ•¸æ“š (æ¨¡æ“¬NewsAPI)
            print("   ç²å–åŠ å¯†è²¨å¹£æ–°è...")
            news_articles = self._fetch_crypto_news()

            # æ­¥é©Ÿ2.2: éæ¿¾æ–°èå…§å®¹
            print("   éæ¿¾æ–°èå…§å®¹...")
            filtered_articles = self._filter_news_articles(news_articles)

            # æ­¥é©Ÿ2.3: ä½¿ç”¨AIåˆ†ææƒ…ç·’
            print("   åˆ†ææ–°èæƒ…ç·’...")
            sentiment_analysis = self._analyze_news_sentiment_with_ai(filtered_articles)

            return sentiment_analysis

        except Exception as e:
            print(f"ç²å–å’Œåˆ†ææ–°èæƒ…ç·’æ™‚å‡ºéŒ¯: {e}")
            return {
                "error": str(e),
                "shortTermSentiment": {"category": "Neutral", "score": 0.0, "rationale": "ç„¡æ³•ç²å–æ–°èæ•¸æ“š"},
                "longTermSentiment": {"category": "Neutral", "score": 0.0, "rationale": "ç„¡æ³•ç²å–æ–°èæ•¸æ“š"}
            }

    def _fetch_crypto_news(self) -> list:
        """ç²å–åŠ å¯†è²¨å¹£æ–°è (æ¨¡æ“¬NewsAPI)"""
        try:
            # åœ¨å¯¦éš›å¯¦ç¾ä¸­ï¼Œé€™è£¡æœƒèª¿ç”¨NewsAPI
            # url = "https://newsapi.org/v2/everything"
            # params = {
            #     "q": "Crypto OR Coindesk OR Bitcoin OR blocktempo",
            #     "from": (datetime.now() - timedelta(days=3)).strftime("%Y-%m-%d"),
            #     "sortBy": "popularity",
            #     "apiKey": "your_api_key"
            # }

            # ç›®å‰ä½¿ç”¨æ¨¡æ“¬æ–°èæ•¸æ“š
            mock_articles = [
                {
                    "title": "æ¯”ç‰¹å¹£çªç ´é—œéµé˜»åŠ›ä½ï¼Œæ©Ÿæ§‹æŠ•è³‡è€…æŒçºŒå¢æŒ",
                    "description": "æœ€æ–°æ•¸æ“šé¡¯ç¤ºï¼Œæ¯”ç‰¹å¹£æˆåŠŸçªç ´é‡è¦æŠ€è¡“é˜»åŠ›ä½ï¼ŒåŒæ™‚æ©Ÿæ§‹æŠ•è³‡è€…æŒçºŒå¢åŠ æ¯”ç‰¹å¹£æŒå€‰ï¼Œå¸‚å ´æƒ…ç·’è½‰ç‚ºæ¨‚è§€ã€‚"
                },
                {
                    "title": "ä»¥å¤ªåŠç¶²çµ¡å‡ç´šé€²å±•é †åˆ©ï¼ŒDeFiç”Ÿæ…‹ç³»çµ±è“¬å‹ƒç™¼å±•",
                    "description": "ä»¥å¤ªåŠæœ€æ–°ç¶²çµ¡å‡ç´šé †åˆ©å®Œæˆï¼Œäº¤æ˜“è²»ç”¨é¡¯è‘—é™ä½ï¼ŒDeFiå”è­°æ´»èºåº¦å‰µæ–°é«˜ã€‚"
                },
                {
                    "title": "åŠ å¯†è²¨å¹£ç›£ç®¡ç’°å¢ƒé€æ¼¸æ˜æœ—ï¼Œå¸‚å ´æµå‹•æ€§å……è¶³",
                    "description": "å…¨çƒä¸»è¦ç¶“æ¿Ÿé«”å°åŠ å¯†è²¨å¹£ç›£ç®¡æ”¿ç­–é€æ¼¸æ˜ç¢ºï¼Œç‚ºå¸‚å ´ç™¼å±•æä¾›äº†æ›´å¥½çš„æ³•å¾‹æ¡†æ¶ã€‚"
                },
                {
                    "title": "ä¸»è¦äº¤æ˜“æ‰€å ±å‘ŠåŠ å¯†è²¨å¹£æµå…¥é‡å‰µæ–°é«˜",
                    "description": "å¤šå®¶ä¸»è¦åŠ å¯†è²¨å¹£äº¤æ˜“æ‰€å ±å‘Šï¼Œè¿‘æœŸæ©Ÿæ§‹å’Œé›¶å”®æŠ•è³‡è€…çš„è³‡é‡‘æµå…¥é‡é”åˆ°æ­·å²æ–°é«˜ã€‚"
                },
                {
                    "title": "å€å¡ŠéˆæŠ€è¡“åœ¨å‚³çµ±é‡‘èé ˜åŸŸæ‡‰ç”¨åŠ é€Ÿ",
                    "description": "è¶Šä¾†è¶Šå¤šçš„å‚³çµ±é‡‘èæ©Ÿæ§‹é–‹å§‹æ¡ç”¨å€å¡ŠéˆæŠ€è¡“ï¼Œæ¨å‹•æ•´å€‹åŠ å¯†è²¨å¹£ç”Ÿæ…‹ç³»çµ±çš„ç™¼å±•ã€‚"
                }
            ]

            return {"articles": mock_articles}

        except Exception as e:
            print(f"ç²å–æ–°èæ™‚å‡ºéŒ¯: {e}")
            return {"articles": []}

    def _filter_news_articles(self, news_data: dict) -> list:
        """éæ¿¾æ–°èæ–‡ç«  (æ¨¡æ“¬N8Nçš„trimming newsç¯€é»)"""
        try:
            articles = news_data.get("articles", [])
            filtered_articles = []

            for article in articles:
                filtered_article = {
                    "title": article.get("title", ""),
                    "description": article.get("description", "")
                }
                filtered_articles.append(filtered_article)

            return filtered_articles

        except Exception as e:
            print(f"éæ¿¾æ–°èæ–‡ç« æ™‚å‡ºéŒ¯: {e}")
            return []

    def _analyze_news_sentiment_with_ai(self, filtered_articles: list) -> Dict[str, Any]:
        """ä½¿ç”¨AIåˆ†ææ–°èæƒ…ç·’ (æ¨¡æ“¬N8Nçš„OpenAIç¯€é»)"""
        try:
            # æª¢æŸ¥æ˜¯å¦ç‚ºæ¸¬è©¦æ¨¡å¼
            if self.api_key and self.api_key.lower() in ["test", "demo", "æ¸¬è©¦"]:
                print("   ä½¿ç”¨æ¨¡æ“¬æƒ…ç·’åˆ†æ...")
                return self._generate_mock_sentiment_analysis()

            # æ§‹å»ºæƒ…ç·’åˆ†ææç¤ºè© (å®Œå…¨è¤‡è£½N8Nå·¥ä½œæµçš„æç¤ºè©)
            sentiment_prompt = self._build_sentiment_analysis_prompt(filtered_articles)

            # èª¿ç”¨Google Geminié€²è¡Œæƒ…ç·’åˆ†æ
            print("   èª¿ç”¨Google Geminiåˆ†ææ–°èæƒ…ç·’...")
            response = self._call_gemini_model_with_retry(sentiment_prompt)

            # è§£æAIå›æ‡‰ (æ¨¡æ“¬N8Nçš„æª¢é©—ç¯€é»)
            parsed_sentiment = self._parse_sentiment_response(response)

            return parsed_sentiment

        except Exception as e:
            print(f"AIæƒ…ç·’åˆ†ææ™‚å‡ºéŒ¯: {e}")
            return self._generate_mock_sentiment_analysis()

    def _build_sentiment_analysis_prompt(self, filtered_articles: list) -> str:
        """æ§‹å»ºæƒ…ç·’åˆ†ææç¤ºè© (å®Œå…¨è¤‡è£½N8Nå·¥ä½œæµ)"""
        articles_json = json.dumps(filtered_articles, ensure_ascii=False)

        prompt = f"""You are a highly intelligent and accurate sentiment analyzer specializing in cryptocurrency markets. Analyze the sentiment of the provided text using a two-part approach:

1. Short-Term Sentiment:
    -Evaluate the immediate market reaction, recent news impact, and technical volatility.
    -Determine a sentiment category"positive","Neutral", or "Negative".
    -Calculate a numerical score between -1 (extremly negative) and 1 (extremely positive).
    -Provide a detailed rationale explaining the short-term sentiment.

2. Long-Term Sentiment:
    -Evaluate the overall market outlook, fundamentals, and regulatory developments.
    -Determine the sentiment category: "Positive", "Neutral", or "Negative".
    -Calculate a numerical score between -1 (extremely negative) and 1 (extremely positive).
    -Provide a detailed rationale explaining the long-term sentiment.

Your output must be exactly a JSON object with exactly two keys: "shortTermSentiment" and "longTermSentiment". Do not output anything else.

For example, your output should look like: {{
  "shortTermSentiment": {{
    "category": "Positive",
    "score": 0.7,
    "rationale": "..."
}},
  "longTermSentiment": {{
    "category": "Neutral",
    "score": 0.1,
    "rationale": "..."
  }}
}}.
Now, analyze the following text and produce your JSON output: {articles_json}"""

        return prompt

    def _parse_sentiment_response(self, response: str) -> Dict[str, Any]:
        """è§£ææƒ…ç·’åˆ†æå›æ‡‰ (æ¨¡æ“¬N8Nçš„æª¢é©—ç¯€é»)"""
        try:
            # æ‰¾åˆ°JSONé–‹å§‹å’ŒçµæŸä½ç½®
            json_start = response.find('{')
            if json_start == -1:
                raise ValueError("ç„¡æ³•åœ¨å›æ‡‰ä¸­æ‰¾åˆ°JSONé–‹é ­")

            json_end = response.rfind('}') + 1
            json_part = response[json_start:json_end]

            # è§£æJSON
            parsed_response = json.loads(json_part)

            return {
                "shortTermSentiment": parsed_response.get("shortTermSentiment", {}),
                "longTermSentiment": parsed_response.get("longTermSentiment", {})
            }

        except Exception as e:
            print(f"è§£ææƒ…ç·’åˆ†æå›æ‡‰æ™‚å‡ºéŒ¯: {e}")
            return self._generate_mock_sentiment_analysis()

    def _generate_mock_sentiment_analysis(self) -> Dict[str, Any]:
        """ç”Ÿæˆæ¨¡æ“¬æƒ…ç·’åˆ†æçµæœ"""
        return {
            "shortTermSentiment": {
                "category": "Positive",
                "score": 0.3,
                "rationale": "è¿‘æœŸåŠ å¯†è²¨å¹£å¸‚å ´è¡¨ç¾ç©©å®šï¼Œæ©Ÿæ§‹æŠ•è³‡è€…æŒçºŒå¢æŒï¼ŒçŸ­æœŸæƒ…ç·’åå‘æ¨‚è§€ã€‚"
            },
            "longTermSentiment": {
                "category": "Positive",
                "score": 0.4,
                "rationale": "ç›£ç®¡ç’°å¢ƒé€æ¼¸æ˜æœ—ï¼Œå€å¡ŠéˆæŠ€è¡“æ‡‰ç”¨åŠ é€Ÿï¼Œé•·æœŸå‰æ™¯çœ‹å¥½ã€‚"
            }
        }

    def _combine_technical_and_sentiment_data(self, multi_timeframe_data: Dict[str, Any],
                                            news_sentiment: Dict[str, Any]) -> Dict[str, Any]:
        """æ­¥é©Ÿ3: åˆä½µæŠ€è¡“æ•¸æ“šå’Œæƒ…ç·’æ•¸æ“š (æ¨¡æ“¬N8Nçš„Code2ç¯€é»)"""
        try:
            all_candles = multi_timeframe_data.get("allCandles", [])

            # æå–æƒ…ç·’æ•¸æ“š
            sentiment_content = {
                "shortTermSentiment": news_sentiment.get("shortTermSentiment", {}),
                "longTermSentiment": news_sentiment.get("longTermSentiment", {})
            }

            combined_data = {
                "allCandles": all_candles,
                "content": sentiment_content
            }

            print(f"   âœ… æ•¸æ“šåˆä½µå®Œæˆ - Kç·šæ•¸æ“š: {len(all_candles)} å€‹æ™‚é–“æ¡†æ¶")
            return combined_data

        except Exception as e:
            print(f"åˆä½µæ•¸æ“šæ™‚å‡ºéŒ¯: {e}")
            return {
                "allCandles": [],
                "content": {}
            }

    def _generate_professional_trading_analysis(self, symbol: str, combined_data: Dict[str, Any],
                                              detail_level: str) -> Dict[str, Any]:
        """æ­¥é©Ÿ4: ç”Ÿæˆå°ˆæ¥­äº¤æ˜“åˆ†æ (æ¨¡æ“¬N8Nçš„AI Agentç¯€é»)"""
        try:
            # æ§‹å»ºå°ˆæ¥­åˆ†ææç¤ºè© (å®Œå…¨è¤‡è£½N8Nå·¥ä½œæµçš„AI Agentæç¤ºè©)
            professional_prompt = self._build_professional_analysis_prompt(symbol, combined_data)

            # èª¿ç”¨Google Geminié€²è¡Œå°ˆæ¥­åˆ†æ
            print("   èª¿ç”¨Google Geminié€²è¡Œå°ˆæ¥­äº¤æ˜“åˆ†æ...")
            analysis_result = self._call_gemini_model_with_retry(professional_prompt)

            # æ ¼å¼åŒ–å›æ‡‰ä¸¦ç§»é™¤HTMLæ¨™ç±¤
            formatted_result = self._format_response(analysis_result, symbol, "å¤šæ™‚é–“æ¡†æ¶")

            # ç§»é™¤HTMLæ¨™ç±¤
            formatted_result['analysis_text'] = self._remove_html_tags(formatted_result['analysis_text'])

            return formatted_result

        except Exception as e:
            print(f"ç”Ÿæˆå°ˆæ¥­åˆ†ææ™‚å‡ºéŒ¯: {e}")
            return {
                "analysis_text": f"ç”Ÿæˆå°ˆæ¥­åˆ†ææ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}",
                "generated_at": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                "symbol": symbol,
                "timeframe": "å¤šæ™‚é–“æ¡†æ¶",
                "status": "error"
            }

    def _build_professional_analysis_prompt(self, symbol: str, combined_data: Dict[str, Any]) -> str:
        """æ§‹å»ºå°ˆæ¥­åˆ†ææç¤ºè© (å®Œå…¨è¤‡è£½N8Nå·¥ä½œæµçš„AI Agentæç¤ºè©)"""

        all_candles = combined_data.get("allCandles", [])
        sentiment_content = combined_data.get("content", {})

        # ç²å–ç•¶å‰æ™‚é–“
        current_time = datetime.now().strftime("%m/%d/%Y at %I:%M%p")

        # æ§‹å»ºä¸­æ–‡ç‰ˆå°ˆæ¥­åˆ†ææç¤ºè©
        prompt = f"""ä»¥ä¸‹æ˜¯ {symbol} çš„ç¶œåˆå¸‚å ´æ•¸æ“šä¾›æ‚¨åƒè€ƒï¼š

æŠ€è¡“æ•¸æ“šï¼š
{json.dumps(all_candles, ensure_ascii=False)}

æƒ…ç·’åˆ†æï¼š
{json.dumps(sentiment_content, ensure_ascii=False)}

é€™æ˜¯ä¸€å€‹JSONæ•¸çµ„ï¼Œæ¯å€‹å…ƒç´ éƒ½æ˜¯åŠ å¯†è²¨å¹£è³‡ç”¢çš„Kç·šæ•¸æ“šå°è±¡ã€‚æ¯å€‹å°è±¡å…·æœ‰ä»¥ä¸‹çµæ§‹ï¼š
- timeframe: "15m"ã€"1h" æˆ– "1d"
- candles: æŒ‰ä»¥ä¸‹é †åºæ’åˆ—çš„æ•¸å€¼æ•¸çµ„ï¼š
  [openTime, open, high, low, close, volume, closeTime, quoteVolume, trades, takerBuyBaseVolume, takerBuyQuoteVolume, ignore]

æƒ…ç·’æ•¸æ“šï¼šJSONæ•¸çµ„æœ«å°¾é‚„åŒ…å«åŸºæ–¼éå»7å¤©åŠ å¯†è²¨å¹£æ–°èæ¨™é¡Œèšåˆçš„é•·æœŸå’ŒçŸ­æœŸæƒ…ç·’åˆ†æã€‚

è«‹åŸ·è¡Œä»¥ä¸‹åˆ†ææ­¥é©Ÿï¼š

æ•¸æ“šåˆ†çµ„ï¼š

å°‡Kç·šæ•¸æ“šå°è±¡æŒ‰æ™‚é–“æ¡†æ¶åˆ†ç‚ºä¸‰çµ„ï¼š
- çŸ­æœŸæ•¸æ“šï¼š"15m" Kç·š
- ä¸­æœŸæ•¸æ“šï¼š"1h" Kç·š
- é•·æœŸæ•¸æ“šï¼š"1d" Kç·š

è©³ç´°æ•¸æ“šåˆ†æï¼š

çŸ­æœŸåˆ†æï¼š
ä½¿ç”¨15åˆ†é˜Kç·šï¼ˆçµåˆ1å°æ™‚Kç·šçš„æ”¯æ’æ€§è¦‹è§£ï¼‰è©•ä¼°æ³¢å‹•æ€§ä¸¦ç¢ºå®šè¿‘æœŸæ”¯æ’å’Œé˜»åŠ›ä½ã€‚åœ¨åˆ†æä¸­ï¼Œå°‡å‚³çµ±æ»¯å¾ŒæŒ‡æ¨™ï¼ˆå¦‚MACDã€RSIå’ŒOBVï¼‰ä½œç‚ºç¢ºèªå·¥å…·ï¼Œçµåˆç›´æ¥åƒ¹æ ¼è¡Œç‚ºå…ƒç´ â€”â€”å¦‚é—œéµæ”¯æ’/é˜»åŠ›å€åŸŸã€è¶¨å‹¢ç·šå’ŒèƒŒé›¢æ¨¡å¼ã€‚å°ˆæ³¨æ–¼é€™äº›åŸºæ–¼åƒ¹æ ¼çš„ä¿¡è™Ÿä¾†æ•æ‰å³æ™‚æƒ…ç·’å’Œçµæ§‹æ€§æ°´å¹³ã€‚

é•·æœŸåˆ†æï¼š
ä½¿ç”¨æ—¥ç·šKç·šï¼ˆä»¥åŠ1å°æ™‚Kç·šçš„ç›¸é—œè¦‹è§£ï¼‰è©•ä¼°æ•´é«”å¸‚å ´æ–¹å‘å’Œä¸»è¦æ”¯æ’/é˜»åŠ›å€åŸŸã€‚åœ¨é€™è£¡ï¼Œæ•´åˆé•·æœŸè¶¨å‹¢ç·šå’ŒèƒŒé›¢ä¿¡è™Ÿä»¥åŠæ»¯å¾ŒæŒ‡æ¨™ï¼Œä»¥äº†è§£æ›´å»£æ³›çš„å¸‚å ´èƒŒæ™¯å’Œæ½›åœ¨çš„çµæ§‹æ€§è®ŠåŒ–ã€‚

ç”Ÿæˆäº¤æ˜“å»ºè­°ï¼š

ç¾è²¨äº¤æ˜“ï¼š

æ“ä½œï¼šï¼ˆè²·å…¥ã€è³£å‡ºæˆ–æŒæœ‰ï¼‰
é€²å ´åƒ¹æ ¼ï¼š
æ­¢ææ°´å¹³ï¼š
æ­¢ç›ˆæ°´å¹³ï¼š
ç†ç”±ï¼šæä¾›æ¥µå…¶è©³ç´°çš„å»ºè­°è§£é‡‹ã€‚å°‡ç†ç”±åˆ†ç‚ºä¸‰å€‹éƒ¨åˆ†ï¼š
  a. ä¸»è¦ä¿¡è™Ÿï¼šæè¿°é—œéµåƒ¹æ ¼è¡Œç‚ºè¦‹è§£ï¼ˆæ”¯æ’/é˜»åŠ›å€åŸŸã€è¶¨å‹¢ç·šçªç ´æˆ–åå½ˆã€èƒŒé›¢æ¨¡å¼ï¼‰ã€‚
  b. æ»¯å¾ŒæŒ‡æ¨™ï¼šè§£é‡‹æŒ‡æ¨™ï¼ˆMACDã€RSIã€OBVç­‰ï¼‰å¦‚ä½•ç¢ºèªæˆ–è£œå……é€™äº›ä¿¡è™Ÿã€‚
  c. æƒ…ç·’åˆ†æï¼šè¨è«–æˆäº¤é‡è¶¨å‹¢ã€å¸‚å ´æƒ…ç·’å’Œå®è§€å› ç´ ã€‚å°‡é€™äº›å…ƒç´ çµåˆæˆä¸€å€‹ç¶œåˆè§£é‡‹ã€‚

æ§“æ¡¿äº¤æ˜“ï¼š

å€‰ä½ï¼šï¼ˆå¤šé ­æˆ–ç©ºé ­ï¼‰
å»ºè­°æ§“æ¡¿ï¼šï¼ˆä¾‹å¦‚3å€ã€5å€ç­‰ï¼‰
é€²å ´åƒ¹æ ¼ï¼š
æ­¢ææ°´å¹³ï¼š
æ­¢ç›ˆæ°´å¹³ï¼š
ç†ç”±ï¼šæä¾›è©³ç´°è§£é‡‹ï¼ŒåŒæ¨£å°‡ç†ç”±åˆ†ç‚ºï¼š
  a. ä¸»è¦åƒ¹æ ¼è¡Œç‚ºä¿¡è™Ÿï¼šæ¦‚è¿°é—œéµæ”¯æ’/é˜»åŠ›æ°´å¹³ã€è¶¨å‹¢ç·šå’ŒèƒŒé›¢æ¨¡å¼ã€‚
  b. æ»¯å¾ŒæŒ‡æ¨™ç¢ºèªï¼šæè¿°æŒ‡æ¨™å¦‚ä½•é©—è­‰é€™äº›ä¿¡è™Ÿã€‚
  c. æƒ…ç·’å’Œå®è§€åˆ†æï¼šåŒ…æ‹¬æˆäº¤é‡è¶¨å‹¢ã€æ•´é«”å¸‚å ´æƒ…ç·’å’Œæ›´å»£æ³›ç¶“æ¿Ÿå› ç´ çš„åˆ†æã€‚

è¼¸å‡ºæ ¼å¼ï¼š
ä»¥ç´”æ–‡æœ¬å½¢å¼è¿”å›æœ€çµ‚çµæœï¼Œä¸ä½¿ç”¨ä»»ä½•HTMLæ¨™ç±¤ã€‚

æ¯å€‹éƒ¨åˆ†æ¨™é¡Œï¼ˆä¾‹å¦‚"ç¾è²¨å»ºè­°"ï¼‰ä½¿ç”¨ç²—é«”ã€‚
æ¯å€‹å­éƒ¨åˆ†ï¼ˆä¾‹å¦‚ä¸»è¦ä¿¡è™Ÿã€æ»¯å¾ŒæŒ‡æ¨™ã€æƒ…ç·’åˆ†æï¼‰ä¹Ÿä½¿ç”¨ç²—é«”ã€‚åœ¨éƒ¨åˆ†ä¹‹é–“ä½¿ç”¨æ¸…æ™°çš„æ›è¡Œç¬¦å’Œé …ç›®ç¬¦è™Ÿä»¥ä¿æŒæ¸…æ™°ã€‚

è«‹æŒ‰ä»¥ä¸‹æ ¼å¼è¼¸å‡ºï¼ˆä¸è¦ä½¿ç”¨HTMLæ¨™ç±¤ï¼‰ï¼š

{symbol} åˆ†æå ±å‘Š - {current_time}

**ç¾è²¨äº¤æ˜“å»ºè­°**

**çŸ­æœŸï¼š**
- æ“ä½œï¼š...
- é€²å ´åƒ¹æ ¼ï¼š...
- æ­¢æï¼š...
- æ­¢ç›ˆï¼š...
- ç†ç”±ï¼š
  - **ä¸»è¦ä¿¡è™Ÿï¼š** ...
  - **æ»¯å¾ŒæŒ‡æ¨™ï¼š** ...
  - **æƒ…ç·’åˆ†æï¼š** ...

**é•·æœŸï¼š**
- æ“ä½œï¼š...
- é€²å ´åƒ¹æ ¼ï¼š...
- æ­¢æï¼š...
- æ­¢ç›ˆï¼š...
- ç†ç”±ï¼š
  - **ä¸»è¦ä¿¡è™Ÿï¼š** ...
  - **æ»¯å¾ŒæŒ‡æ¨™ï¼š** ...
  - **æƒ…ç·’åˆ†æï¼š** ...

**æ§“æ¡¿äº¤æ˜“å»ºè­°**

**çŸ­æœŸï¼š**
- å€‰ä½ï¼š...
- æ§“æ¡¿ï¼š...
- é€²å ´åƒ¹æ ¼ï¼š...
- æ­¢æï¼š...
- æ­¢ç›ˆï¼š...
- ç†ç”±ï¼š
  - **ä¸»è¦åƒ¹æ ¼è¡Œç‚ºä¿¡è™Ÿï¼š** ...
  - **æ»¯å¾ŒæŒ‡æ¨™ç¢ºèªï¼š** ...
  - **æƒ…ç·’å’Œå®è§€åˆ†æï¼š** ...

**é•·æœŸï¼š**
- å€‰ä½ï¼š...
- æ§“æ¡¿ï¼š...
- é€²å ´åƒ¹æ ¼ï¼š...
- æ­¢æï¼š...
- æ­¢ç›ˆï¼š...
- ç†ç”±ï¼š
  - **ä¸»è¦åƒ¹æ ¼è¡Œç‚ºä¿¡è™Ÿï¼š** ...
  - **æ»¯å¾ŒæŒ‡æ¨™ç¢ºèªï¼š** ...
  - **æƒ…ç·’å’Œå®è§€åˆ†æï¼š** ...

è«‹ç¢ºä¿æ‰€æœ‰åˆ†æéƒ½åŸºæ–¼æä¾›çš„å¯¦éš›Kç·šæ•¸æ“šå’Œæƒ…ç·’åˆ†æï¼Œä¸¦ä½¿ç”¨ç¹é«”ä¸­æ–‡å›æ‡‰ã€‚"""

        return prompt

    def _remove_html_tags(self, text: str) -> str:
        """ç§»é™¤HTMLæ¨™ç±¤"""
        try:
            import re
            # ç§»é™¤æ‰€æœ‰HTMLæ¨™ç±¤
            clean_text = re.sub(r'<[^>]+>', '', text)
            # ç§»é™¤å¤šé¤˜çš„ç©ºè¡Œ
            clean_text = re.sub(r'\n\s*\n', '\n\n', clean_text)
            return clean_text.strip()
        except Exception as e:
            print(f"ç§»é™¤HTMLæ¨™ç±¤æ™‚å‡ºéŒ¯: {e}")
            return text

    def _prepare_time_range_info(self, data: pd.DataFrame, symbol: str, timeframe: str) -> Dict[str, Any]:
        """éšæ®µ1: æº–å‚™æ™‚é–“ç¯„åœä¿¡æ¯"""
        try:
            start_date = data.index[0]
            end_date = data.index[-1]
            duration = end_date - start_date

            return {
                "symbol": symbol,
                "timeframe": timeframe,
                "start_date": start_date.strftime("%Y-%m-%d"),
                "end_date": end_date.strftime("%Y-%m-%d"),
                "start_datetime": start_date.strftime("%Y-%m-%d %H:%M:%S"),
                "end_datetime": end_date.strftime("%Y-%m-%d %H:%M:%S"),
                "duration_days": duration.days,
                "duration_hours": duration.total_seconds() / 3600,
                "data_points": len(data),
                "analysis_period": f"{start_date.strftime('%Y-%m-%d')} è‡³ {end_date.strftime('%Y-%m-%d')}"
            }
        except Exception as e:
            print(f"æº–å‚™æ™‚é–“ç¯„åœä¿¡æ¯æ™‚å‡ºéŒ¯: {e}")
            return {
                "symbol": symbol,
                "timeframe": timeframe,
                "error": str(e)
            }

    def _prepare_basic_data_summary(self, data: pd.DataFrame) -> Dict[str, Any]:
        """éšæ®µ1: æº–å‚™åŸºç¤æ•¸æ“šæ‘˜è¦"""
        try:
            # åŸºæœ¬åƒ¹æ ¼çµ±è¨ˆ
            open_price = float(data['Open'].iloc[0])
            close_price = float(data['Close'].iloc[-1])
            high_price = float(data['High'].max())
            low_price = float(data['Low'].min())

            # åƒ¹æ ¼è®ŠåŒ–
            price_change = close_price - open_price
            price_change_pct = (price_change / open_price) * 100

            # æˆäº¤é‡çµ±è¨ˆ
            volume_stats = {}
            if 'Volume' in data.columns and not data['Volume'].isna().all():
                volume_stats = {
                    "avg_volume": float(data['Volume'].mean()),
                    "max_volume": float(data['Volume'].max()),
                    "min_volume": float(data['Volume'].min()),
                    "total_volume": float(data['Volume'].sum()),
                    "volume_trend": "ä¸Šå‡" if data['Volume'].iloc[-5:].mean() > data['Volume'].iloc[:5].mean() else "ä¸‹é™"
                }

            # Kç·šæ•¸æ“šæ‘˜è¦ï¼ˆæ¯10%å–æ¨£ï¼‰
            sample_size = max(10, len(data) // 10)
            sample_indices = [int(i * len(data) / sample_size) for i in range(sample_size)]
            if sample_indices[-1] != len(data) - 1:
                sample_indices.append(len(data) - 1)

            kline_data = []
            for i in sample_indices:
                row = data.iloc[i]
                kline_data.append({
                    "timestamp": data.index[i].strftime("%Y-%m-%d %H:%M"),
                    "open": float(row['Open']),
                    "high": float(row['High']),
                    "low": float(row['Low']),
                    "close": float(row['Close']),
                    "volume": float(row.get('Volume', 0))
                })

            return {
                "price_summary": {
                    "open": open_price,
                    "close": close_price,
                    "high": high_price,
                    "low": low_price,
                    "change": price_change,
                    "change_pct": price_change_pct,
                    "range_pct": ((high_price - low_price) / low_price) * 100
                },
                "volume_summary": volume_stats,
                "kline_sample": kline_data,
                "data_quality": {
                    "total_candles": len(data),
                    "missing_data": data.isnull().sum().sum(),
                    "data_completeness": (1 - data.isnull().sum().sum() / (len(data) * len(data.columns))) * 100
                }
            }
        except Exception as e:
            print(f"æº–å‚™åŸºç¤æ•¸æ“šæ‘˜è¦æ™‚å‡ºéŒ¯: {e}")
            return {"error": str(e)}

    def _perform_technical_analysis(self, data: pd.DataFrame) -> Dict[str, Any]:
        """éšæ®µ2: åŸ·è¡ŒæŠ€è¡“æŒ‡æ¨™åˆ†æ"""
        try:
            close = data['Close']
            high = data['High']
            low = data['Low']
            volume = data.get('Volume', pd.Series([0] * len(data)))

            # ç§»å‹•å¹³å‡ç·š
            ema_12 = close.ewm(span=12).mean()
            ema_26 = close.ewm(span=26).mean()
            ema_50 = close.ewm(span=50).mean() if len(data) >= 50 else close.ewm(span=len(data)//2).mean()
            ema_200 = close.ewm(span=200).mean() if len(data) >= 200 else close.ewm(span=len(data)//4).mean()

            # RSIè¨ˆç®—
            delta = close.diff()
            gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()
            loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()
            rs = gain / loss
            rsi = 100 - (100 / (1 + rs))

            # MACDè¨ˆç®—
            macd_line = ema_12 - ema_26
            signal_line = macd_line.ewm(span=9).mean()
            histogram = macd_line - signal_line

            # å¸ƒæ—å¸¶
            bb_period = min(20, len(data)//2)
            bb_middle = close.rolling(window=bb_period).mean()
            bb_std = close.rolling(window=bb_period).std()
            bb_upper = bb_middle + (bb_std * 2)
            bb_lower = bb_middle - (bb_std * 2)

            # æˆäº¤é‡æŒ‡æ¨™
            volume_ma = volume.rolling(window=min(20, len(data)//2)).mean()

            # ç•¶å‰å€¼
            current_values = {
                "ema_12": float(ema_12.iloc[-1]) if not ema_12.isna().iloc[-1] else None,
                "ema_26": float(ema_26.iloc[-1]) if not ema_26.isna().iloc[-1] else None,
                "ema_50": float(ema_50.iloc[-1]) if not ema_50.isna().iloc[-1] else None,
                "ema_200": float(ema_200.iloc[-1]) if not ema_200.isna().iloc[-1] else None,
                "rsi": float(rsi.iloc[-1]) if not rsi.isna().iloc[-1] else None,
                "macd": float(macd_line.iloc[-1]) if not macd_line.isna().iloc[-1] else None,
                "macd_signal": float(signal_line.iloc[-1]) if not signal_line.isna().iloc[-1] else None,
                "macd_histogram": float(histogram.iloc[-1]) if not histogram.isna().iloc[-1] else None,
                "bb_upper": float(bb_upper.iloc[-1]) if not bb_upper.isna().iloc[-1] else None,
                "bb_middle": float(bb_middle.iloc[-1]) if not bb_middle.isna().iloc[-1] else None,
                "bb_lower": float(bb_lower.iloc[-1]) if not bb_lower.isna().iloc[-1] else None,
                "current_price": float(close.iloc[-1])
            }

            # æŠ€è¡“ä¿¡è™Ÿ
            signals = {
                "ema_trend": "å¤šé ­" if current_values["ema_12"] and current_values["ema_26"] and current_values["ema_12"] > current_values["ema_26"] else "ç©ºé ­",
                "rsi_signal": "è¶…è²·" if current_values["rsi"] and current_values["rsi"] > 70 else "è¶…è³£" if current_values["rsi"] and current_values["rsi"] < 30 else "ä¸­æ€§",
                "macd_signal": "è²·å…¥" if current_values["macd"] and current_values["macd_signal"] and current_values["macd"] > current_values["macd_signal"] else "è³£å‡º",
                "bb_position": "ä¸Šè»Œé™„è¿‘" if current_values["current_price"] > current_values["bb_upper"] * 0.98 else "ä¸‹è»Œé™„è¿‘" if current_values["current_price"] < current_values["bb_lower"] * 1.02 else "ä¸­è»Œå€é–“",
                "volume_trend": "æ”¾é‡" if volume.iloc[-5:].mean() > volume_ma.iloc[-1] * 1.2 else "ç¸®é‡" if volume.iloc[-5:].mean() < volume_ma.iloc[-1] * 0.8 else "æ­£å¸¸"
            }

            return {
                "indicators": current_values,
                "signals": signals,
                "analysis_summary": {
                    "trend_strength": abs(current_values.get("macd_histogram", 0)),
                    "momentum": "å¼·å‹¢" if abs(current_values.get("rsi", 50) - 50) > 20 else "æº«å’Œ",
                    "volatility": "é«˜" if (current_values.get("bb_upper", 0) - current_values.get("bb_lower", 0)) / current_values.get("bb_middle", 1) > 0.1 else "ä½"
                }
            }
        except Exception as e:
            print(f"åŸ·è¡ŒæŠ€è¡“åˆ†ææ™‚å‡ºéŒ¯: {e}")
            return {"error": str(e)}

    def _analyze_market_sentiment(self, symbol: str, time_range_info: Dict[str, Any]) -> Dict[str, Any]:
        """éšæ®µ3: åˆ†æå¸‚å ´æƒ…ç·’å’Œæ–°èï¼ˆæ¨¡æ“¬å¯¦ç¾ï¼‰"""
        try:
            # åœ¨å¯¦éš›å¯¦ç¾ä¸­ï¼Œé€™è£¡æœƒèª¿ç”¨æ–°èAPIç²å–ç›¸é—œæ–°è
            # ç›®å‰æä¾›æ¨¡æ“¬çš„å¸‚å ´æƒ…ç·’åˆ†æ

            start_date = time_range_info.get("start_date", "")
            end_date = time_range_info.get("end_date", "")

            # æ¨¡æ“¬æ–°èæƒ…ç·’åˆ†æ
            sentiment_score = 0.1  # ä¸­æ€§åæ­£é¢

            # æ ¹æ“šäº¤æ˜“å°èª¿æ•´æƒ…ç·’
            if 'BTC' in symbol.upper():
                sentiment_score = 0.2  # BTCé€šå¸¸è¼ƒæ¨‚è§€
                market_events = [
                    "æ©Ÿæ§‹æŠ•è³‡è€…æŒçºŒå¢æŒæ¯”ç‰¹å¹£",
                    "æ¯”ç‰¹å¹£ETFäº¤æ˜“é‡å‰µæ–°é«˜",
                    "ä¸»è¦äº¤æ˜“æ‰€å ±å‘Šæ¯”ç‰¹å¹£æµå…¥å¢åŠ "
                ]
                sentiment_summary = "æ•´é«”å¸‚å ´å°æ¯”ç‰¹å¹£ä¿æŒæ¨‚è§€æ…‹åº¦"
            elif 'ETH' in symbol.upper():
                sentiment_score = 0.15
                market_events = [
                    "ä»¥å¤ªåŠç¶²çµ¡å‡ç´šé€²å±•é †åˆ©",
                    "DeFiç”Ÿæ…‹ç³»çµ±æŒçºŒç™¼å±•",
                    "æ©Ÿæ§‹å°ä»¥å¤ªåŠèˆˆè¶£å¢åŠ "
                ]
                sentiment_summary = "ä»¥å¤ªåŠåŸºæœ¬é¢ä¿æŒå¼·å‹"
            else:
                sentiment_score = 0.0
                market_events = [
                    "åŠ å¯†è²¨å¹£å¸‚å ´æ•´é«”ç©©å®š",
                    "ç›£ç®¡ç’°å¢ƒé€æ¼¸æ˜æœ—",
                    "å¸‚å ´æµå‹•æ€§å……è¶³"
                ]
                sentiment_summary = "å¸‚å ´æƒ…ç·’ç›¸å°ä¸­æ€§"

            return {
                "analysis_period": f"{start_date} è‡³ {end_date}",
                "sentiment_score": sentiment_score,  # -1åˆ°1ä¹‹é–“ï¼Œ-1æœ€æ‚²è§€ï¼Œ1æœ€æ¨‚è§€
                "sentiment_label": "æ¨‚è§€" if sentiment_score > 0.1 else "æ‚²è§€" if sentiment_score < -0.1 else "ä¸­æ€§",
                "market_events": market_events,
                "sentiment_summary": sentiment_summary,
                "confidence_level": "ä¸­ç­‰",  # æ¨¡æ“¬æ•¸æ“šçš„ç½®ä¿¡åº¦
                "data_source": "æ¨¡æ“¬æ•¸æ“š",
                "news_count": len(market_events),
                "sentiment_trend": "ç©©å®š"
            }
        except Exception as e:
            print(f"åˆ†æå¸‚å ´æƒ…ç·’æ™‚å‡ºéŒ¯: {e}")
            return {
                "error": str(e),
                "sentiment_score": 0,
                "sentiment_label": "æœªçŸ¥"
            }

    def _generate_comprehensive_analysis(self, time_range_info: Dict[str, Any],
                                       basic_data: Dict[str, Any],
                                       technical_analysis: Dict[str, Any],
                                       news_sentiment: Dict[str, Any],
                                       detail_level: str) -> Dict[str, Any]:
        """éšæ®µ4: ç”Ÿæˆç¶œåˆåˆ†æå ±å‘Š"""
        try:
            # æ§‹å»ºç¶œåˆåˆ†ææç¤ºè©
            comprehensive_prompt = self._build_comprehensive_prompt(
                time_range_info, basic_data, technical_analysis, news_sentiment, detail_level
            )

            # èª¿ç”¨AIæ¨¡å‹ç”Ÿæˆåˆ†æ
            print("æ­£åœ¨èª¿ç”¨AIæ¨¡å‹ç”Ÿæˆç¶œåˆåˆ†æ...")
            analysis_result = self._call_gemini_model_with_retry(comprehensive_prompt)

            # æ ¼å¼åŒ–å›æ‡‰
            return self._format_response(
                analysis_result,
                time_range_info.get("symbol", "æœªçŸ¥"),
                time_range_info.get("timeframe", "æœªçŸ¥")
            )

        except Exception as e:
            print(f"ç”Ÿæˆç¶œåˆåˆ†ææ™‚å‡ºéŒ¯: {e}")
            return {
                "analysis_text": f"ç”Ÿæˆç¶œåˆåˆ†ææ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}",
                "generated_at": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                "symbol": time_range_info.get("symbol", "æœªçŸ¥"),
                "timeframe": time_range_info.get("timeframe", "æœªçŸ¥"),
                "status": "error"
            }

    def _build_comprehensive_prompt(self, time_range_info: Dict[str, Any],
                                  basic_data: Dict[str, Any],
                                  technical_analysis: Dict[str, Any],
                                  news_sentiment: Dict[str, Any],
                                  detail_level: str) -> str:
        """æ§‹å»ºç¶œåˆåˆ†ææç¤ºè©"""

        symbol = time_range_info.get("symbol", "æœªçŸ¥")
        timeframe = time_range_info.get("timeframe", "æœªçŸ¥")
        analysis_period = time_range_info.get("analysis_period", "æœªçŸ¥æœŸé–“")

        # æå–é—œéµæ•¸æ“š
        price_summary = basic_data.get("price_summary", {})
        indicators = technical_analysis.get("indicators", {})
        signals = technical_analysis.get("signals", {})

        prompt = f"""ä½ æ˜¯ä¸€ä½è³‡æ·±çš„åŠ å¯†è²¨å¹£åˆ†æå¸«ï¼Œè«‹åŸºæ–¼ä»¥ä¸‹å®Œæ•´çš„æ•¸æ“šåˆ†æå° {symbol} é€²è¡Œå°ˆæ¥­çš„å¸‚å ´åˆ†æã€‚

=== ğŸ“Š åŸºç¤æ•¸æ“šåˆ†æ ===
äº¤æ˜“å°: {symbol}
æ™‚é–“æ¡†æ¶: {timeframe}
åˆ†ææœŸé–“: {analysis_period}

ä»¥ä¸‹æ•¸æ“šæ˜¯ç”± {analysis_period} æ™‚é–“ç¯„åœçš„ {symbol} {timeframe} å¹£åƒ¹èµ°å‹¢æƒ…æ³ï¼š

åƒ¹æ ¼è¡¨ç¾:
- æœŸåˆåƒ¹æ ¼: ${price_summary.get('open', 0):,.2f}
- æœŸæœ«åƒ¹æ ¼: ${price_summary.get('close', 0):,.2f}
- æœ€é«˜åƒ¹æ ¼: ${price_summary.get('high', 0):,.2f}
- æœ€ä½åƒ¹æ ¼: ${price_summary.get('low', 0):,.2f}
- åƒ¹æ ¼è®ŠåŒ–: {price_summary.get('change_pct', 0):+.2f}%
- åƒ¹æ ¼å€é–“: {price_summary.get('range_pct', 0):.2f}%

=== ğŸ“ˆ æŠ€è¡“æŒ‡æ¨™åˆ†æ ===
ç¶“éè¨ˆç®—çš„åŸºç¤æŠ€è¡“æŒ‡æ¨™æ•¸æ“šï¼š

ç§»å‹•å¹³å‡ç·š:
- EMA12: ${indicators.get('ema_12', 0):,.2f}
- EMA26: ${indicators.get('ema_26', 0):,.2f}
- EMA50: ${indicators.get('ema_50', 0):,.2f}
- EMA200: ${indicators.get('ema_200', 0):,.2f}
- å‡ç·šè¶¨å‹¢: {signals.get('ema_trend', 'æœªçŸ¥')}

å‹•é‡æŒ‡æ¨™:
- RSI: {indicators.get('rsi', 0):.1f} ({signals.get('rsi_signal', 'æœªçŸ¥')})
- MACD: {indicators.get('macd', 0):.4f}
- MACDä¿¡è™Ÿç·š: {indicators.get('macd_signal', 0):.4f}
- MACDæŸ±ç‹€åœ–: {indicators.get('macd_histogram', 0):+.4f}
- MACDä¿¡è™Ÿ: {signals.get('macd_signal', 'æœªçŸ¥')}

å¸ƒæ—å¸¶:
- ä¸Šè»Œ: ${indicators.get('bb_upper', 0):,.2f}
- ä¸­è»Œ: ${indicators.get('bb_middle', 0):,.2f}
- ä¸‹è»Œ: ${indicators.get('bb_lower', 0):,.2f}
- åƒ¹æ ¼ä½ç½®: {signals.get('bb_position', 'æœªçŸ¥')}

æˆäº¤é‡:
- æˆäº¤é‡è¶¨å‹¢: {signals.get('volume_trend', 'æœªçŸ¥')}

=== ğŸ“° å¸‚å ´æƒ…ç·’åˆ†æ ===
{analysis_period} æœŸé–“çš„å¸‚å ´æƒ…ç·’å’Œæ–°èåˆ†æï¼š

æƒ…ç·’æŒ‡æ¨™:
- æ•´é«”æƒ…ç·’: {news_sentiment.get('sentiment_label', 'æœªçŸ¥')} (è©•åˆ†: {news_sentiment.get('sentiment_score', 0):+.2f})
- æƒ…ç·’ç¸½çµ: {news_sentiment.get('sentiment_summary', 'ç„¡æ•¸æ“š')}
- å¸‚å ´äº‹ä»¶: {', '.join(news_sentiment.get('market_events', []))}

=== ğŸ¯ åˆ†æè¦æ±‚ ===
è«‹çµåˆä»¥ä¸Šä¸‰å€‹å±¤é¢çš„æ•¸æ“šï¼ˆåŸºç¤åƒ¹æ ¼æ•¸æ“šã€æŠ€è¡“æŒ‡æ¨™ã€å¸‚å ´æƒ…ç·’ï¼‰ï¼Œé€²è¡Œ{detail_level}ç¨‹åº¦çš„ç¶œåˆåˆ†æï¼ŒåŒ…æ‹¬ï¼š

1. **æ•´é«”è¶¨å‹¢åˆ¤æ–·**: åŸºæ–¼åƒ¹æ ¼è¡Œç‚ºå’ŒæŠ€è¡“æŒ‡æ¨™çš„ç¶œåˆåˆ¤æ–·
2. **é—œéµæ”¯æ’é˜»åŠ›ä½**: çµåˆæŠ€è¡“æŒ‡æ¨™ç¢ºå®šé‡è¦åƒ¹ä½
3. **æŠ€è¡“æŒ‡æ¨™è§£è®€**: æ·±å…¥åˆ†æå„é …æŠ€è¡“æŒ‡æ¨™çš„å«ç¾©
4. **å¸‚å ´æƒ…ç·’å½±éŸ¿**: åˆ†ææ–°èæƒ…ç·’å°åƒ¹æ ¼èµ°å‹¢çš„å½±éŸ¿
5. **é¢¨éšªè©•ä¼°**: ç¶œåˆæŠ€è¡“å’ŒåŸºæœ¬é¢çš„é¢¨éšªåˆ†æ
6. **çŸ­æœŸå±•æœ›**: 1-7å¤©çš„èµ°å‹¢é æ¸¬
7. **äº¤æ˜“å»ºè­°**: åŸºæ–¼ç¶œåˆåˆ†æçš„æ“ä½œå»ºè­°

=== ğŸ“‹ åˆ†æåŸå‰‡ ===
- è«‹å…ˆåˆ†æåŸºç¤æŠ€è¡“æŒ‡æ¨™ï¼Œå†çµåˆå¸‚å ´æƒ…ç·’é€²è¡Œç¶œåˆåˆ¤æ–·
- é‡é»é—œæ³¨æŠ€è¡“æŒ‡æ¨™ä¹‹é–“çš„ç›¸äº’é©—è­‰
- è€ƒæ…®å¸‚å ´æƒ…ç·’å°æŠ€è¡“åˆ†æçš„å½±éŸ¿
- æä¾›å®¢è§€ã€å°ˆæ¥­çš„åˆ†æï¼Œé¿å…éåº¦æ¨‚è§€æˆ–æ‚²è§€
- æ˜ç¢ºæŒ‡å‡ºåˆ†æçš„é™åˆ¶æ€§å’Œä¸ç¢ºå®šæ€§

è«‹ç”¨ç¹é«”ä¸­æ–‡æä¾›å°ˆæ¥­ã€è©³ç´°çš„åˆ†æå ±å‘Šã€‚"""

        return prompt

    def _validate_data(self, data: pd.DataFrame) -> bool:
        """é©—è­‰è¼¸å…¥æ•¸æ“šçš„æœ‰æ•ˆæ€§"""
        required_columns = ['Open', 'High', 'Low', 'Close']

        if data.empty:
            print("éŒ¯èª¤: æ•¸æ“šç‚ºç©º")
            return False

        missing_columns = [col for col in required_columns if col not in data.columns]
        if missing_columns:
            print(f"éŒ¯èª¤: ç¼ºå°‘å¿…è¦çš„åˆ—: {missing_columns}")
            return False

        if len(data) < 10:
            print("è­¦å‘Š: æ•¸æ“šé»å¤ªå°‘ï¼Œå¯èƒ½å½±éŸ¿åˆ†æè³ªé‡")

        return True

    def _prepare_data_summary(self, data: pd.DataFrame) -> Dict[str, Any]:
        """æº–å‚™æ•¸æ“šæ‘˜è¦ï¼Œé¿å…ç™¼é€éå¤šæ•¸æ“š"""
        try:
            # è¨ˆç®—åŸºæœ¬çµ±è¨ˆæ•¸æ“š
            summary = {
                "start_date": data.index[0].strftime("%Y-%m-%d %H:%M"),
                "end_date": data.index[-1].strftime("%Y-%m-%d %H:%M"),
                "duration_days": (data.index[-1] - data.index[0]).days,
                "data_points": len(data),
                "price_start": float(data['Close'].iloc[0]),
                "price_end": float(data['Close'].iloc[-1]),
                "price_min": float(data['Low'].min()),
                "price_max": float(data['High'].max()),
                "price_change_pct": float(((data['Close'].iloc[-1] / data['Close'].iloc[0]) - 1) * 100),
                "volatility": float(data['Close'].pct_change().std() * 100),
            }

            # å®‰å…¨åœ°è™•ç†æˆäº¤é‡æ•¸æ“š
            if 'Volume' in data.columns and not data['Volume'].isna().all():
                summary["volume_avg"] = float(data['Volume'].mean())
                summary["volume_max"] = float(data['Volume'].max())
                summary["volume_trend"] = "ä¸Šå‡" if data['Volume'].iloc[-10:].mean() > data['Volume'].iloc[:10].mean() else "ä¸‹é™"
            else:
                summary["volume_avg"] = 0
                summary["volume_max"] = 0
                summary["volume_trend"] = "ç„¡æ•¸æ“š"

            # è¨ˆç®—æŠ€è¡“æŒ‡æ¨™
            summary.update(self._calculate_technical_indicators(data))

            # æ·»åŠ é—œéµåƒ¹æ ¼é»ï¼ˆæ™ºèƒ½æ¡æ¨£ï¼‰
            key_points = self._get_key_price_points(data)
            summary["key_points"] = key_points

            # æ·»åŠ è¶¨å‹¢ç‰¹å¾µ
            summary["trend_features"] = self._extract_trend_features(data)

            return summary

        except Exception as e:
            print(f"æº–å‚™æ•¸æ“šæ‘˜è¦æ™‚å‡ºéŒ¯: {e}")
            # è¿”å›åŸºæœ¬æ‘˜è¦
            return {
                "start_date": str(data.index[0]),
                "end_date": str(data.index[-1]),
                "data_points": len(data),
                "price_start": float(data['Close'].iloc[0]),
                "price_end": float(data['Close'].iloc[-1]),
                "error": str(e)
            }

    def _calculate_technical_indicators(self, data: pd.DataFrame) -> Dict[str, Any]:
        """è¨ˆç®—åŸºæœ¬æŠ€è¡“æŒ‡æ¨™"""
        try:
            close = data['Close']
            high = data['High']
            low = data['Low']

            # ç§»å‹•å¹³å‡ç·š
            ma_short = close.rolling(window=min(20, len(data)//4)).mean()
            ma_long = close.rolling(window=min(50, len(data)//2)).mean()

            # RSI (ç°¡åŒ–ç‰ˆæœ¬)
            delta = close.diff()
            gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()
            loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()
            rs = gain / loss
            rsi = 100 - (100 / (1 + rs))

            return {
                "ma_short_current": float(ma_short.iloc[-1]) if not ma_short.isna().iloc[-1] else None,
                "ma_long_current": float(ma_long.iloc[-1]) if not ma_long.isna().iloc[-1] else None,
                "ma_trend": "å¤šé ­" if ma_short.iloc[-1] > ma_long.iloc[-1] else "ç©ºé ­",
                "rsi_current": float(rsi.iloc[-1]) if not rsi.isna().iloc[-1] else None,
                "rsi_signal": "è¶…è²·" if rsi.iloc[-1] > 70 else "è¶…è³£" if rsi.iloc[-1] < 30 else "ä¸­æ€§",
                "price_vs_ma_short": float((close.iloc[-1] / ma_short.iloc[-1] - 1) * 100) if not ma_short.isna().iloc[-1] else None,
                "volatility_recent": float(close.pct_change().tail(20).std() * 100),
            }
        except Exception as e:
            print(f"è¨ˆç®—æŠ€è¡“æŒ‡æ¨™æ™‚å‡ºéŒ¯: {e}")
            return {"error": str(e)}

    def _get_key_price_points(self, data: pd.DataFrame) -> list:
        """æ™ºèƒ½æ¡æ¨£é—œéµåƒ¹æ ¼é»"""
        try:
            # æ ¹æ“šæ•¸æ“šé‡æ±ºå®šæ¡æ¨£ç­–ç•¥
            if len(data) <= 50:
                # å°æ•¸æ“šé›†ï¼šæ¯5å€‹é»å–ä¸€å€‹
                sample_indices = range(0, len(data), max(1, len(data) // 10))
            else:
                # å¤§æ•¸æ“šé›†ï¼šå–é‡è¦é»ä½
                sample_indices = []
                step = len(data) // 20  # æœ€å¤š20å€‹é»
                for i in range(0, len(data), step):
                    sample_indices.append(i)
                # ç¢ºä¿åŒ…å«æœ€å¾Œä¸€å€‹é»
                if sample_indices[-1] != len(data) - 1:
                    sample_indices.append(len(data) - 1)

            key_points = []
            for i in sample_indices:
                row = data.iloc[i]
                key_points.append({
                    "date": data.index[i].strftime("%Y-%m-%d %H:%M"),
                    "open": float(row['Open']),
                    "high": float(row['High']),
                    "low": float(row['Low']),
                    "close": float(row['Close']),
                    "volume": float(row.get('Volume', 0))
                })

            return key_points

        except Exception as e:
            print(f"ç²å–é—œéµåƒ¹æ ¼é»æ™‚å‡ºéŒ¯: {e}")
            return []

    def _extract_trend_features(self, data: pd.DataFrame) -> Dict[str, Any]:
        """æå–è¶¨å‹¢ç‰¹å¾µ"""
        try:
            close = data['Close']

            # è¨ˆç®—è¶¨å‹¢å¼·åº¦
            price_change = (close.iloc[-1] / close.iloc[0] - 1) * 100

            # è¨ˆç®—é€£çºŒä¸Šæ¼²/ä¸‹è·Œå¤©æ•¸
            daily_changes = close.pct_change()
            consecutive_up = 0
            consecutive_down = 0

            for change in daily_changes.iloc[-10:]:  # çœ‹æœ€è¿‘10å€‹æ•¸æ“šé»
                if change > 0:
                    consecutive_up += 1
                    consecutive_down = 0
                elif change < 0:
                    consecutive_down += 1
                    consecutive_up = 0

            # æ”¯æ’é˜»åŠ›ä½ï¼ˆç°¡åŒ–ç‰ˆæœ¬ï¼‰
            recent_highs = data['High'].tail(20)
            recent_lows = data['Low'].tail(20)

            return {
                "overall_trend": "ä¸Šå‡" if price_change > 2 else "ä¸‹é™" if price_change < -2 else "æ©«ç›¤",
                "trend_strength": abs(price_change),
                "consecutive_up_periods": consecutive_up,
                "consecutive_down_periods": consecutive_down,
                "recent_high": float(recent_highs.max()),
                "recent_low": float(recent_lows.min()),
                "price_range_pct": float((recent_highs.max() / recent_lows.min() - 1) * 100)
            }

        except Exception as e:
            print(f"æå–è¶¨å‹¢ç‰¹å¾µæ™‚å‡ºéŒ¯: {e}")
            return {"error": str(e)}

    def _build_prompt(self, data_summary: Dict[str, Any], symbol: str, timeframe: str, detail_level: str = "æ¨™æº–") -> str:
        """æ§‹å»ºæç¤ºè©"""

        # æ ¹æ“šè©³ç´°ç¨‹åº¦èª¿æ•´åˆ†æè¦æ±‚
        analysis_requirements = {
            "ç°¡è¦": [
                "1. æ•´é«”è¶¨å‹¢åˆ¤æ–· (ä¸Šå‡/ä¸‹é™/æ©«ç›¤)",
                "2. ç•¶å‰åƒ¹æ ¼ä½ç½®è©•ä¼°",
                "3. ç°¡è¦é¢¨éšªæç¤º"
            ],
            "æ¨™æº–": [
                "1. æ•´é«”è¶¨å‹¢åˆ¤æ–· (ä¸Šå‡/ä¸‹é™/æ©«ç›¤)",
                "2. é—œéµæ”¯æ’å’Œé˜»åŠ›ä½åˆ†æ",
                "3. æŠ€è¡“æŒ‡æ¨™è§£è®€",
                "4. é¢¨éšªè©•ä¼°",
                "5. çŸ­æœŸå±•æœ› (1-7å¤©)",
                "6. äº¤æ˜“å»ºè­° (åƒ…ä¾›åƒè€ƒ)"
            ],
            "è©³ç´°": [
                "1. æ•´é«”è¶¨å‹¢åˆ¤æ–·èˆ‡è¶¨å‹¢å¼·åº¦è©•ä¼°",
                "2. è©³ç´°çš„æ”¯æ’å’Œé˜»åŠ›ä½åˆ†æ",
                "3. å¤šé‡æŠ€è¡“æŒ‡æ¨™ç¶œåˆè§£è®€",
                "4. æˆäº¤é‡åˆ†æ",
                "5. å¸‚å ´æƒ…ç·’å’Œå‹•èƒ½åˆ†æ",
                "6. é¢¨éšªè©•ä¼°èˆ‡é¢¨éšªç®¡ç†å»ºè­°",
                "7. çŸ­æœŸ (1-7å¤©) å’Œä¸­æœŸ (1-4é€±) å±•æœ›",
                "8. å…·é«”çš„é€²å‡ºå ´é»ä½å»ºè­°",
                "9. ä¸åŒæƒ…å¢ƒä¸‹çš„æ‡‰å°ç­–ç•¥"
            ]
        }

        requirements = analysis_requirements.get(detail_level, analysis_requirements["æ¨™æº–"])

        # æ§‹å»ºæŠ€è¡“æŒ‡æ¨™æ‘˜è¦
        tech_summary = ""
        if "ma_short_current" in data_summary and data_summary["ma_short_current"]:
            tech_summary = f"""
æŠ€è¡“æŒ‡æ¨™æ‘˜è¦:
- çŸ­æœŸå‡ç·š: ${data_summary.get('ma_short_current', 'N/A'):.4f}
- é•·æœŸå‡ç·š: ${data_summary.get('ma_long_current', 'N/A'):.4f}
- å‡ç·šè¶¨å‹¢: {data_summary.get('ma_trend', 'N/A')}
- RSI: {data_summary.get('rsi_current', 'N/A'):.1f} ({data_summary.get('rsi_signal', 'N/A')})
- åƒ¹æ ¼ç›¸å°çŸ­æœŸå‡ç·š: {data_summary.get('price_vs_ma_short', 'N/A'):.2f}%
- è¿‘æœŸæ³¢å‹•ç‡: {data_summary.get('volatility_recent', 'N/A'):.2f}%
"""

        # æ§‹å»ºè¶¨å‹¢ç‰¹å¾µæ‘˜è¦
        trend_summary = ""
        if "trend_features" in data_summary and "error" not in data_summary["trend_features"]:
            tf = data_summary["trend_features"]
            trend_summary = f"""
è¶¨å‹¢ç‰¹å¾µ:
- æ•´é«”è¶¨å‹¢: {tf.get('overall_trend', 'N/A')}
- è¶¨å‹¢å¼·åº¦: {tf.get('trend_strength', 'N/A'):.2f}%
- é€£çºŒä¸Šæ¼²é€±æœŸ: {tf.get('consecutive_up_periods', 'N/A')}
- é€£çºŒä¸‹è·Œé€±æœŸ: {tf.get('consecutive_down_periods', 'N/A')}
- è¿‘æœŸé«˜é»: ${tf.get('recent_high', 'N/A'):.4f}
- è¿‘æœŸä½é»: ${tf.get('recent_low', 'N/A'):.4f}
- åƒ¹æ ¼å€é–“: {tf.get('price_range_pct', 'N/A'):.2f}%
"""

        prompt = f"""ä½ æ˜¯ä¸€ä½è³‡æ·±çš„åŠ å¯†è²¨å¹£æŠ€è¡“åˆ†æå°ˆå®¶ï¼Œæ“æœ‰è±å¯Œçš„å¸‚å ´åˆ†æç¶“é©—ã€‚è«‹åŸºæ–¼ä»¥ä¸‹æ•¸æ“šå° {symbol} åœ¨ {timeframe} æ™‚é–“æ¡†æ¶ä¸‹é€²è¡Œå°ˆæ¥­çš„æŠ€è¡“åˆ†æã€‚

=== åŸºæœ¬æ•¸æ“šæ‘˜è¦ ===
äº¤æ˜“å°: {symbol}
æ™‚é–“æ¡†æ¶: {timeframe}
åˆ†ææœŸé–“: {data_summary['start_date']} è‡³ {data_summary['end_date']}
æ•¸æ“šé»æ•¸: {data_summary['data_points']} å€‹
åˆ†æå¤©æ•¸: {data_summary['duration_days']} å¤©

=== åƒ¹æ ¼æ•¸æ“š ===
èµ·å§‹åƒ¹æ ¼: ${data_summary['price_start']:.6f}
çµæŸåƒ¹æ ¼: ${data_summary['price_end']:.6f}
åƒ¹æ ¼è®ŠåŒ–: {data_summary['price_change_pct']:.2f}%
æœ€é«˜åƒ¹: ${data_summary['price_max']:.6f}
æœ€ä½åƒ¹: ${data_summary['price_min']:.6f}
æ•´é«”æ³¢å‹•ç‡: {data_summary['volatility']:.2f}%

=== æˆäº¤é‡æ•¸æ“š ===
å¹³å‡æˆäº¤é‡: {data_summary.get('volume_avg', 0):,.0f}
æœ€å¤§æˆäº¤é‡: {data_summary.get('volume_max', 0):,.0f}
æˆäº¤é‡è¶¨å‹¢: {data_summary.get('volume_trend', 'N/A')}
{tech_summary}
{trend_summary}

=== é—œéµåƒ¹æ ¼é» (æ™‚é–“åºåˆ—) ===
{json.dumps(data_summary.get('key_points', [])[:10], indent=2, ensure_ascii=False)}

=== åˆ†æè¦æ±‚ ===
è«‹æä¾›ä»¥ä¸‹{detail_level}åˆ†æ:
{chr(10).join(requirements)}

=== åˆ†ææŒ‡å°åŸå‰‡ ===
- è«‹åŸºæ–¼æŠ€è¡“åˆ†æåŸç†ï¼Œçµåˆåƒ¹æ ¼è¡Œç‚ºã€æˆäº¤é‡ã€æŠ€è¡“æŒ‡æ¨™é€²è¡Œç¶œåˆåˆ¤æ–·
- åˆ†ææ‡‰å®¢è§€ä¸­æ€§ï¼Œé¿å…éåº¦æ¨‚è§€æˆ–æ‚²è§€çš„é æ¸¬
- æä¾›çš„å»ºè­°åƒ…ä¾›åƒè€ƒï¼Œè«‹æé†’æŠ•è³‡é¢¨éšª
- ä½¿ç”¨å°ˆæ¥­ä½†æ˜“æ‡‚çš„èªè¨€ï¼Œé©åˆæœ‰ä¸€å®šæŠ•è³‡ç¶“é©—çš„ç”¨æˆ¶
- å¦‚æœæ•¸æ“šä¸è¶³æˆ–å­˜åœ¨ç•°å¸¸ï¼Œè«‹æ˜ç¢ºæŒ‡å‡ºé™åˆ¶æ€§

è«‹ç”¨ç¹é«”ä¸­æ–‡å›ç­”ï¼Œä¿æŒå°ˆæ¥­ã€å®¢è§€çš„åˆ†æèªèª¿ã€‚
"""
        return prompt

    def _call_gemini_model_with_retry(self, prompt: str) -> str:
        """èª¿ç”¨Geminiæ¨¡å‹ï¼ˆå¸¶é‡è©¦æ©Ÿåˆ¶ï¼‰"""

        # æª¢æŸ¥æ˜¯å¦ç‚ºæ¸¬è©¦æ¨¡å¼ï¼ˆAPIå¯†é‘°ç‚º "test" æˆ– "demo"ï¼‰
        if self.api_key and self.api_key.lower() in ["test", "demo", "æ¸¬è©¦"]:
            print("æª¢æ¸¬åˆ°æ¸¬è©¦æ¨¡å¼ï¼Œä½¿ç”¨æ¨¡æ“¬AIå›æ‡‰...")
            return self._generate_mock_analysis_response(prompt)

        for attempt in range(self.max_retries):
            try:
                print(f"å˜—è©¦èª¿ç”¨AIæ¨¡å‹ (ç¬¬ {attempt + 1} æ¬¡)...")

                if hasattr(self.model, 'generate_content'):
                    # Google Generative AI
                    response = self.model.generate_content(prompt)
                    if hasattr(response, 'text'):
                        return response.text
                    else:
                        return str(response)
                else:
                    # Vertex AI
                    response = self.model.generate_content(prompt)
                    return response.text

            except Exception as e:
                print(f"ç¬¬ {attempt + 1} æ¬¡èª¿ç”¨å¤±æ•—: {str(e)}")
                if attempt < self.max_retries - 1:
                    print(f"ç­‰å¾… {self.retry_delay} ç§’å¾Œé‡è©¦...")
                    time.sleep(self.retry_delay)
                    self.retry_delay *= 2  # æŒ‡æ•¸é€€é¿
                else:
                    print("æ‰€æœ‰é‡è©¦éƒ½å¤±æ•—äº†")
                    # å¦‚æœæ‰€æœ‰é‡è©¦éƒ½å¤±æ•—ï¼Œæä¾›æ¨¡æ“¬å›æ‡‰ä½œç‚ºå‚™ç”¨
                    print("æä¾›æ¨¡æ“¬åˆ†æä½œç‚ºå‚™ç”¨...")
                    return self._generate_mock_analysis_response(prompt)

        return "èª¿ç”¨AIæ¨¡å‹å¤±æ•—"

    def _generate_mock_analysis_response(self, prompt: str) -> str:
        """ç”Ÿæˆæ¨¡æ“¬çš„åˆ†æå›æ‡‰ï¼ˆç”¨æ–¼æ¸¬è©¦å’Œæ¼”ç¤ºï¼‰"""

        # å¾æç¤ºè©ä¸­æå–åŸºæœ¬ä¿¡æ¯
        symbol = "æœªçŸ¥äº¤æ˜“å°"
        timeframe = "æœªçŸ¥æ™‚é–“æ¡†æ¶"

        # å˜—è©¦å¾æç¤ºè©ä¸­æå–åƒ¹æ ¼ä¿¡æ¯
        current_price = None
        price_range = None

        if "äº¤æ˜“å°:" in prompt:
            try:
                symbol = prompt.split("äº¤æ˜“å°:")[1].split("\n")[0].strip()
            except Exception:
                pass

        if "æ™‚é–“æ¡†æ¶:" in prompt:
            try:
                timeframe = prompt.split("æ™‚é–“æ¡†æ¶:")[1].split("\n")[0].strip()
            except Exception:
                pass

        # å˜—è©¦å¾æç¤ºè©ä¸­æå–åƒ¹æ ¼æ•¸æ“š
        if "ç•¶å‰åƒ¹æ ¼:" in prompt:
            try:
                price_line = prompt.split("ç•¶å‰åƒ¹æ ¼:")[1].split("\n")[0].strip()
                current_price = float(price_line.replace("$", "").replace(",", ""))
            except Exception:
                pass

        # å˜—è©¦å¾æç¤ºè©ä¸­æå–åƒ¹æ ¼ç¯„åœ
        if "åƒ¹æ ¼ç¯„åœ:" in prompt:
            try:
                range_line = prompt.split("åƒ¹æ ¼ç¯„åœ:")[1].split("\n")[0].strip()
                price_range = range_line
            except Exception:
                pass

        # æ ¹æ“šäº¤æ˜“å°è¨­ç½®åˆç†çš„åƒ¹æ ¼ç¯„åœï¼ˆå¦‚æœæ²’æœ‰å¾æ•¸æ“šä¸­æå–åˆ°ï¼‰
        if not current_price:
            if 'BTC' in symbol.upper():
                current_price = 95000
                price_range = "$90,000 - $100,000"
            elif 'ETH' in symbol.upper():
                current_price = 3200
                price_range = "$3,000 - $3,500"
            elif 'SUI' in symbol.upper():
                current_price = 1.02
                price_range = "$0.98 - $1.06"
            elif 'SOL' in symbol.upper():
                current_price = 180
                price_range = "$170 - $190"
            elif 'ADA' in symbol.upper():
                current_price = 0.45
                price_range = "$0.40 - $0.50"
            elif 'DOT' in symbol.upper():
                current_price = 6.5
                price_range = "$6.0 - $7.0"
            else:
                current_price = 1.0
                price_range = "$0.95 - $1.05"

        # ç”Ÿæˆæ¨¡æ“¬åˆ†æ
        mock_response = f"""
# {symbol} æŠ€è¡“åˆ†æå ±å‘Š

## ğŸ“Š æ•´é«”è¶¨å‹¢åˆ¤æ–·
åŸºæ–¼ç•¶å‰æ•¸æ“šåˆ†æï¼Œ{symbol} åœ¨ {timeframe} æ™‚é–“æ¡†æ¶ä¸‹å‘ˆç¾**éœ‡ç›ªæ•´ç†**çš„èµ°å‹¢ç‰¹å¾µã€‚åƒ¹æ ¼åœ¨é—œéµæ”¯æ’å’Œé˜»åŠ›ä½ä¹‹é–“æ³¢å‹•ï¼Œå¸‚å ´æƒ…ç·’ç›¸å°ä¸­æ€§ã€‚

## ğŸ¯ é—œéµæ”¯æ’å’Œé˜»åŠ›ä½åˆ†æ
- **ä¸»è¦é˜»åŠ›ä½**: ç•¶å‰åƒ¹æ ¼ä¸Šæ–¹çš„é‡è¦é˜»åŠ›å€åŸŸ
- **æ¬¡è¦é˜»åŠ›ä½**: çŸ­æœŸå›èª¿å¯èƒ½é‡åˆ°çš„é˜»åŠ›
- **ä¸»è¦æ”¯æ’ä½**: ç•¶å‰åƒ¹æ ¼ä¸‹æ–¹çš„é—œéµæ”¯æ’å€åŸŸ
- **é—œéµæ”¯æ’ä½**: é‡è¦çš„å¿ƒç†æ”¯æ’ä½

## ğŸ“ˆ æŠ€è¡“æŒ‡æ¨™è§£è®€
- **ç§»å‹•å¹³å‡ç·š**: çŸ­æœŸå‡ç·šèˆ‡é•·æœŸå‡ç·šå‘ˆç¾äº¤ç¹”ç‹€æ…‹
- **ç›¸å°å¼·å¼±æŒ‡æ•¸(RSI)**: è™•æ–¼ä¸­æ€§å€åŸŸï¼Œç„¡æ˜é¡¯è¶…è²·è¶…è³£ä¿¡è™Ÿ
- **æˆäº¤é‡**: æˆäº¤é‡è®ŠåŒ–åæ˜ å¸‚å ´åƒèˆ‡åº¦
- **æ³¢å‹•ç‡**: ç•¶å‰æ³¢å‹•ç‡è™•æ–¼åˆç†ç¯„åœå…§

## âš ï¸ é¢¨éšªè©•ä¼°
- **å¸‚å ´é¢¨éšª**: ç•¶å‰å¸‚å ´è™•æ–¼ä¸ç¢ºå®šç‹€æ…‹ï¼Œéœ€è¦å¯†åˆ‡é—œæ³¨
- **æŠ€è¡“é¢¨éšª**: é—œéµæ”¯æ’ä½ç ´ä½å¯èƒ½å¼•ç™¼é€²ä¸€æ­¥ä¸‹è·Œ
- **æµå‹•æ€§é¢¨éšª**: æ³¨æ„æˆäº¤é‡è®ŠåŒ–å°åƒ¹æ ¼çš„å½±éŸ¿

## ğŸ”® çŸ­æœŸå±•æœ› (1-7å¤©)
çŸ­æœŸå…§é è¨ˆåƒ¹æ ¼å°‡åœ¨ç•¶å‰å€é–“å…§éœ‡ç›ªï¼Œç­‰å¾…æ˜ç¢ºçš„æ–¹å‘æ€§çªç ´ã€‚æŠ•è³‡è€…æ‡‰é—œæ³¨ï¼š
- é—œéµæŠ€è¡“ä½çš„çªç ´æƒ…æ³
- æˆäº¤é‡çš„é…åˆç¨‹åº¦
- å¸‚å ´æ•´é«”æƒ…ç·’è®ŠåŒ–

## ğŸ’¡ äº¤æ˜“å»ºè­° (åƒ…ä¾›åƒè€ƒ)
- **è¬¹æ…è§€æœ›**: ç­‰å¾…æ˜ç¢ºçš„è¶¨å‹¢ä¿¡è™Ÿ
- **åˆ†æ‰¹æ“ä½œ**: å¦‚æœ‰æ“ä½œéœ€æ±‚ï¼Œå»ºè­°åˆ†æ‰¹é€²è¡Œ
- **åš´æ ¼æ­¢æ**: è¨­ç½®åˆç†çš„æ­¢æä½æ§åˆ¶é¢¨éšª
- **é—œæ³¨çªç ´**: å¯†åˆ‡é—œæ³¨é—œéµä½çš„çªç ´æƒ…æ³

---
**âš ï¸ é‡è¦æé†’**:
- æœ¬åˆ†æç‚ºæ¨¡æ“¬æ¼”ç¤ºï¼Œåƒ…ä¾›æ¸¬è©¦åŠŸèƒ½ä½¿ç”¨
- å¯¦éš›æŠ•è³‡è«‹ä½¿ç”¨çœŸå¯¦çš„AIåˆ†æçµæœ
- æŠ•è³‡æœ‰é¢¨éšªï¼Œæ±ºç­–éœ€è¬¹æ…
- å»ºè­°çµåˆå¤šç¨®åˆ†ææ–¹æ³•é€²è¡Œåˆ¤æ–·

**ğŸ“ åˆ†æèªªæ˜**: é€™æ˜¯ä¸€å€‹æ¨¡æ“¬çš„æŠ€è¡“åˆ†æå ±å‘Šï¼Œç”¨æ–¼æ¼”ç¤ºèµ°å‹¢åˆ†æåŠŸèƒ½ã€‚åœ¨å¯¦éš›ä½¿ç”¨ä¸­ï¼Œè«‹é…ç½®æœ‰æ•ˆçš„Google APIå¯†é‘°ä»¥ç²å¾—çœŸå¯¦çš„AIåˆ†æçµæœã€‚
"""

        return mock_response.strip()

    def _call_gemini_model(self, prompt: str) -> str:
        """èª¿ç”¨Geminiæ¨¡å‹ï¼ˆèˆŠç‰ˆæœ¬ï¼Œä¿æŒå…¼å®¹æ€§ï¼‰"""
        try:
            if hasattr(self.model, 'generate_content'):
                response = self.model.generate_content(prompt)
                return response.text if hasattr(response, 'text') else str(response)
            else:
                # å‚™ç”¨æ–¹æ³•
                model = aiplatform.GenerativeModel("gemini-1.5-flash")
                response = model.generate_content(prompt)
                return response.text
        except Exception as e:
            print(f"èª¿ç”¨Geminiæ¨¡å‹æ™‚å‡ºéŒ¯: {e}")
            return f"åˆ†æéç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤: {str(e)}"

    def _format_response(self, response: str, symbol: str, timeframe: str) -> Dict[str, Any]:
        """æ ¼å¼åŒ–æ¨¡å‹å›æ‡‰"""
        try:
            # æ¸…ç†å›æ‡‰æ–‡æœ¬
            cleaned_response = response.strip()

            # æª¢æŸ¥å›æ‡‰æ˜¯å¦æœ‰æ•ˆ
            if not cleaned_response or len(cleaned_response) < 50:
                cleaned_response = "AIåˆ†æå›æ‡‰éçŸ­æˆ–ç„¡æ•ˆï¼Œè«‹æª¢æŸ¥APIé…ç½®æˆ–é‡è©¦ã€‚"

            return {
                "analysis_text": cleaned_response,
                "generated_at": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                "symbol": symbol,
                "timeframe": timeframe,
                "status": "success",
                "word_count": len(cleaned_response)
            }
        except Exception as e:
            print(f"æ ¼å¼åŒ–å›æ‡‰æ™‚å‡ºéŒ¯: {e}")
            return {
                "analysis_text": f"æ ¼å¼åŒ–åˆ†æçµæœæ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}",
                "generated_at": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                "symbol": symbol,
                "timeframe": timeframe,
                "status": "error"
            }